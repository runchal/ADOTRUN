{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Natural language processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our word counts would be more interesting if we could reason better about the *language* in the text, not just the individual characters. For example, if we knew the parts of speech of individual words, we could exclude words that are determiners, conjunctions, etc. from the count. If we knew what kinds of things the words were referring to, we could count how many times particular characters or settings are referenced.\n",
    "\n",
    "To do this, we need to do a bit of Natural Language Processing. [More notes and opinions on this.](https://gist.github.com/aparrish/f21f6abbf2367e8eb23438558207e1c3)\n",
    "\n",
    "Most natural language processing is done with the aid of third-party libraries. We're going to use one called spaCy. To use spaCy, you first need to import it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in your text using the following line of code! (Remember to replace `pg84.txt` with the filename of your own text file.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace with the name of your own text file, then run this cell with CTRL+Enter.\n",
    "text = open(\"sotu2012_edited.txt\").read() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, use spaCy to parse it. (This might take a while, depending on the size of your text.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right off the bat, the spaCy library gives us access to a number of interesting units of text:\n",
    "\n",
    "* All of the sentences (`doc.sents`)\n",
    "* All of the words (`doc`)\n",
    "* All of the \"named entitites,\" like names of places, people, #brands, etc. (`doc.ents`)\n",
    "* All of the \"noun chunks,\" i.e., nouns in the text plus surrounding matter like adjectives and articles\n",
    "\n",
    "The cell below, we extract these into variables so we can play around with them a little bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences = list(doc.sents)\n",
    "words = [w for w in list(doc) if w.is_alpha]\n",
    "noun_chunks = list(doc.noun_chunks)\n",
    "entities = list(doc.ents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this information in hand, we can answer interesting questions like: how many sentences are in the text?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can go thru every sentence in sentences and print each one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mr. Speaker, Mr. Vice President, members of Congress, distinguished\n",
      "guests, and fellow Americans.\n",
      "\n",
      "\n",
      "cats like cheese.\n",
      "dogs like potatos.\n",
      "\n",
      "\n",
      "Last month, I went to Andrews Air Force Base and welcomed home some of\n",
      "our last troops to serve in Iraq.\n",
      "Together, we offered a final, proud\n",
      "salute to the colors under which more than a million of our fellow\n",
      "citizens fought - and several thousand gave their lives.\n",
      "\n",
      "\n",
      "chair is smelly.\n",
      "\n",
      "\n",
      "We gather tonight knowing that this generation of heroes has made the\n",
      "United States safer and more respected around the world.\n",
      "For the first\n",
      "time in nine years, there are no Americans fighting in Iraq.\n",
      "For the\n",
      "first time in two decades, Osama bin Laden is not a threat to this\n",
      "country.\n",
      "Most of al Qaeda's top lieutenants have been defeated.\n",
      "The\n",
      "Taliban's momentum has been broken, and some troops in Afghanistan have\n",
      "begun to come home.\n",
      "\n",
      "\n",
      "These achievements are a testament to the courage, selflessness, and\n",
      "teamwork of America's Armed Forces.\n",
      "At a time when too many of our\n",
      "institutions have let us down, they exceed all expectations.\n",
      "They're\n",
      "not consumed with personal ambition.\n",
      "They don't obsess over their\n",
      "differences.\n",
      "They focus on the mission at hand.\n",
      "They work together.\n",
      "\n",
      "\n",
      "Imagine what we could accomplish if we followed their example.\n",
      "Think\n",
      "about the America within our reach: A country that leads the world in\n",
      "educating its people.\n",
      "An America that attracts a new generation of\n",
      "high-tech manufacturing and high-paying jobs.\n",
      "A future where we're in\n",
      "control of our own energy, and our security and prosperity aren't so\n",
      "tied to unstable parts of the world.\n",
      "An economy built to last, where\n",
      "hard work pays off, and responsibility is rewarded.\n",
      "\n",
      "\n",
      "We can do this.\n",
      "I know we can, because we've done it before.\n",
      "At the end\n",
      "of World War II, when another generation of heroes returned home from\n",
      "combat, they built the strongest economy and middle class the world has\n",
      "ever known.\n",
      "My grandfather, a veteran of Patton's Army, got the chance\n",
      "to go to college on the GI Bill.\n",
      "My grandmother, who worked on a bomber\n",
      "assembly line, was part of a workforce that turned out the best\n",
      "products on Earth.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for item in sentences:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wat if we only printed sentences that started with the word \"We\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We gather tonight knowing that this generation of heroes has made the\n",
      "United States safer and more respected around the world.\n",
      "We can do this.\n"
     ]
    }
   ],
   "source": [
    "for item in sentences:\n",
    "    if item[0].text == \"We\":\n",
    "         print(item.text)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'spacy.tokens.token.Token'>\n",
      "\n",
      "[members, guests, cats, cheese, dogs, potatos, month, troops, salute, colors, fellow, citizens, lives, chair, tonight, generation, heroes, world, time, years, time, decades, threat, country, lieutenants, momentum, troops, achievements, testament, courage, selflessness, teamwork, time, institutions, expectations, ambition, differences, mission, hand, what, example, reach, country, world, people, generation, tech, manufacturing, jobs, future, control, energy, security, prosperity, parts, world, economy, work, responsibility, end, generation, heroes, combat, economy, class, world, grandfather, veteran, chance, college, grandmother, who, bomber, assembly, line, part, workforce, products]\n"
     ]
    }
   ],
   "source": [
    "nouns = [w for w in words if w.pos_ == \"NOUN\"]\n",
    "\n",
    "#what data-type is a word in nouns? oh no! it's a weird spacy token thing.\n",
    "print(type(nouns[0]))\n",
    "\n",
    "#print a break\n",
    "print()\n",
    "\n",
    "#print all nouns\n",
    "print(nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'spacy.tokens.token.Token'>\n",
      "\n",
      "['members', 'guests', 'cats', 'cheese', 'dogs', 'potatos', 'month', 'troops', 'salute', 'colors', 'fellow', 'citizens', 'lives', 'chair', 'tonight', 'generation', 'heroes', 'world', 'time', 'years', 'time', 'decades', 'threat', 'country', 'lieutenants', 'momentum', 'troops', 'achievements', 'testament', 'courage', 'selflessness', 'teamwork', 'time', 'institutions', 'expectations', 'ambition', 'differences', 'mission', 'hand', 'what', 'example', 'reach', 'country', 'world', 'people', 'generation', 'tech', 'manufacturing', 'jobs', 'future', 'control', 'energy', 'security', 'prosperity', 'parts', 'world', 'economy', 'work', 'responsibility', 'end', 'generation', 'heroes', 'combat', 'economy', 'class', 'world', 'grandfather', 'veteran', 'chance', 'college', 'grandmother', 'who', 'bomber', 'assembly', 'line', 'part', 'workforce', 'products']\n"
     ]
    }
   ],
   "source": [
    "#here we add a .text after w in order to turn the words into strings.\n",
    "nouns_str = [w.text for w in words if w.pos_ == \"NOUN\"]\n",
    "\n",
    "#what data-type is a word in nouns? yayy! we want str. the words have quotes now!\n",
    "print(type(nouns[0]))\n",
    "\n",
    "#print a break\n",
    "print()\n",
    "\n",
    "#print all nouns\n",
    "print(nouns_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cats like cheese.\n",
      "dogs like potatos.\n",
      "\n",
      "\n",
      "chair is smelly.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#for every sentence in sentences, if the first word of the sentence is in the nouns_str list, print that sentence\n",
    "\n",
    "for item in sentences:\n",
    "    if item[0].text in nouns_str:\n",
    "         print(item.text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
